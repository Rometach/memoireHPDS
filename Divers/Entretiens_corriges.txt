\textbf{RV ---} Was für Musik hören Sie gern?

\textbf{KHZ ---} Ich höre sehr viel Musik, vor allem professionell, weil ich eben sehr viel mit Studenten zu tun habe, mich sehr viel informiere, was momentan gerade komponiert und produziert wird. Das ist das professionelle Musikhören. Das mache ich ständig, das ist natürlich sehr unterschiedlich, das geht natürlich in erste Linie um neue Musik, elektronische Musik, experimentelle Musik\dots~Aber es gibt doch Musik, die ich zu meinem Vergnügen höre. Und das sind eigentlich Sachen, die ganz weit weg sind von dem, was ich selber mache. Das ist eigentlich die Musik, die ich früher gehört habe, als Jugendlicher, oder junger Erwachsener, habe mich ich eine Zeitlang sehr intensiv mit bestimmten Arten von avancierter Rockmusik beschäftigt, und diese Sachen höre ich immer noch gern. Also, was ist das, zum Beispiel\dots~Gentle Giant, oder, eine meiner Lieblingsgruppen ist eine Band aus Deutschland, Can, das waren Krautrock-Exponenten, die mit Stockhausen auch gearbeitet haben. Also, sie waren teilweise Schüler von Stockhausen, und über diese Band bin ich eben auf Stockhausen gekommen, und das war eigentlich die Brücke für mich zu der elektronischen Musik, über diese Schiene.

\textbf{RV ---} Können Sie mir Ihre Entdeckung von Perecs Werk erzählen?

\textbf{KHZ ---} Ich kann mich erinnern, das war noch in meiner Studienzeit, in den achtziger Jahren, ich habe mich beschäftigt mit allen möglichen Formen von Algorithmen, auch zur Generierung von musikalischen Strukturen, und habe mich auch schon interessiert für experimentelle Literatur, die mit ähnlichen Methoden arbeitet. In Österreich gibt es eine Formation, die hat sich nach dem zweiten Weltkrieg, in den fünfziger Jahren in Wien, zusammengefunden, die ist die Wiener Gruppe. Da waren ganz berühmte österreichische Autoren versammelt, wie H.C. Artmann, Konrad Bayer, Gerhard Rühm\dots~die haben einen sehr strukturellen Zugang zur Literatur gehabt, und haben versucht, mit bestimmten modernen Methoden Texte zu dekonstruieren, Texte zu konstruieren, und in dem Zusammenhang hat mich dann jemand aufmerksam gemacht, dass es in Frankreich, in Paris, eine ähnliche Gruppe gibt, nämlich die OuLiPo, die mit so ähnlichen Ideen arbeitet, die waren später, aber die Artmann möglicherweise auch irgendwie beeinflussten. Und über diese Informationen bin ich dann zu Georges Perec gekommen, und dann habe ich viele Sachen von ihm gelesen, und mich auch ziemlich eine Zeit lang intensiv mit seinen Arbeiten beschäftigt. Obwohl ich nicht Französisch kann, habe ich das Buch "La disparition" zweisprachig gelesen, also nicht komplett, aber ich habe immer die deutsche Übersetzung und das französische Original parallel gelesen, und bin darauf gekommen, dass das unglaublich gut übersetzt ist.

\textbf{RV ---} Dafür müssen Sie doch ein bisschen Französisch können!

\textbf{KHZ ---} Ja, ein bisschen kann ich, ich habe auch in Frankreich eine Zeit lang gelebt, in Paris im Ircam gearbeitet. Ich kann grundlegende Sachen, aber ich kann nicht wirklich sprechen. Also, ich kann einiges lesen. Also, es gibt diese geniale Übersetzung von Eugen Helmlé, der zweisprachig war, er war Deutsch-Franzose, und das hat mich total beeindruckt, dass es möglich ist, ein so kompliziertes Buch, und ohne den Buchstabe E, den häufigsten Buchstaben in der deutschen und französischen Sprache, dass das Buch sogar ins Deutsche übersetzt werden kann, ohne den Buchstaben E. Das sind bestimmte Dinge, die mich halt irgendwie bei Perec fasziniert haben.

\textbf{RV ---} Wann haben Sie zum ersten Mal einen Computer benutzt, und wann haben sie gelernt, zu programmieren?

\textbf{KHZ ---} Das war während meiner Studienzeit in den achtziger Jahren. Ich habe 1971 begonnen, Musikwissenschaft zu studieren, und habe dann erst 1981 die Aufnahmeprüfung gemacht in der Akademie für Komposition. Und während meines Musikwissenschaftsstudiums hatte ich einen Freund, mit dem ich bis heute befreundet bin, Gerhard Eckel, der ist mittlerweile Professor für Computermusik in Graz an der Kunstuniversität. Und Gerhard hat schon sehr früh mit Computern gearbeitet, wir haben in unserem Musikwissenschaftsinstitut eine Abteilung gehabt, die hat sich mit Klangforschung beschäftigt, und die hatten in der Akademie der Wissenschaften ein Labor, und hatten damals schon mit Mainframe-Computer gearbeitet, also mit großen Rechnern, und Gerhard war von Anfang an als Student dort involviert, und hat da mitgearbeitet, mitgeholfen, hat danach programmiert und C gelernt, und sehr früh begonnen. Und ich kann mich erinnern, dass ich vielleicht 1985 mir den ersten Computer gekauft habe. Und davor habe ich den Computer total abgelehnt. Ich habe in den ersten Zeiten meines Studiums, von 1981 bis 1983, bei einem sehr traditionellen Lehrer Musiktheorieunterricht gehabt, und habe ich mich nur interessiert für alte Musik. Kontrapunkt, Motetten, und mittelalterliche Musik\dots~Das habe ich im Musikwissenschaftsstudium auch gut gelernt, das hat mich sehr fasziniert, also wirklich frühmittelalterliche Musik, Perotin, französische Notre-Dame-Schule des dreizehnten Jahrhunderts. Und dann kam der Gerhard, und hat gesagt: mit dem Computer kann man ganz interessante Sachen machen, und ich habe gesagt: das kommt gar nicht in Frage, das ist alles vorgestellt und so\dots~Und irgendwann war es dann so, dass wir beschlossen haben, wir machen gemeinsam eine Gruppe, eine Komponistengruppe, und werden dann gemeinsame Konzerte veranstalten, und in der Zeit habe ich mich schon für elektronische Musik interessiert, das war über Stockhausen, diese Konnexion. Und wir hatten gemeinsam, der Gerhard und ich, eine Ausbildung gemacht über elektronische Musik. Das war alles noch Analog, ohne Computer, mit Tonbandmaschinen. Bei der Gelegenheit hatten wir dann eine Gruppe gegründet, mit dem tollen Namen "Kybernikos". Und einer von uns, der hat für eine Computerzeitschrift getestet, und hatte immer zu Hause die neuesten Computer. Das muss man sich mal vorstellen, es war 1984-1985, da sind die PCs gerade herausgekommen, das war nicht eine Sache, die verbreitet war. Und eines Sommers hat er mich gebeten, einen Monat lang seine Wohnung zu hüten, Pflanzen zu gießen, und hat gesagt: du kannst aber an diesem Computer arbeiten. Das war ein Siemens Desktop-Computer, und ich habe gerade begonnen, meine Dissertation zu schreiben, und bin darauf gekommen, wie praktisch das ist, wenn man den Computer als Schreibmaschine benutzt, und auch damit Texte leichter verfassen kann oder verändern kann. Und als er dann zurückgekommen ist, habe ich ihm gesagt: ich bin jetzt vom Computer abhängig, ich brauche auch so was, was soll ich mir kaufen? Er hat gesagt: ja, du musst noch zwei Monate warten, dann kommt ein neues Gerät auf dem Markt, das würde ich dir empfehlen, das heißt Atari. Im Grunde ist der aus dem Apple Macintosh herausgekommen. Apple gab es schon früher, aber Apple Macintosh. Und der Apple war damals für normale Studenten viel zu teuer. Der Atari hat ein Drittel gekostet, immer noch viel Geld, hatte ein graphisches "graphical user interface", und ich habe mir den gekauft. Das Problem war, es gab keine Software. Das einzige, was darauf war, war ein Adventure Game, ein "Textadventure", und Basic. Und dann hat mein Freund Gerhard gesagt: jetzt hast du einen Computer, jetzt können wir da mal Experimente machen, ich habe mich damals interessiert für Algorithmen und serielle Musik, und dann haben wir eben begonnen, mit Basic so bestimmte Strukturen zu generieren, kleine Programme zu schreiben, und da habe ich gesehen, wie unglaublich interessant das ist. Und habe ziemlich bald Logo entdeckt, das ist eine Programmiersprache, eine Erfindung von Marvin Minsky, sehr berühmter Computerwissenschaftler vom MIT, und der Schweizer Pädagoge und Psychologe Jean Piaget. Es war eine geniale Zusammenarbeit. Piaget war eben ein Pädagoge, und hat sich gefragt, wie kann man Kindern Werkzeuge in die Hand geben, mit denen Sie ihre Welt oder ihre Umwelt begreifen oder auch noch konstruieren können, also es war die Idee der Micro-Worlds. Also, Software, es ging ihm letztendlich um Software, als Mittel um Erkenntnis zu bekommen, oder Probleme zu analysieren und durch das Verstehen oder durch die Analyse eines Problems findet man eine Lösung, und diese Lösung kann man programmieren, das heißt, man baut sich ein Werkzeug. Und die Idee von Marvin Minsky und Piaget war, eine Programmiersprache zu erfinden, die einfach und intuitiv ist, und die den Kindern oder den Menschen, die sie benutzen, ermöglicht, ihre eigenen Programme zu schreiben, und diese Programmcodes, die sie schreiben, weiter zu verwenden. Es war natürlich Interpreter-Sprache. Und eines der Ausgabe-Instrumente war dieses sogenannte "turtle", also so eine Art Maus, also das Gegenteil von einer Maus, also der Maus, die sozusagen nicht mit der Hand bedient wird, sondern der Computer steuert sie, und die Maus oder diese "turtle" hat einen Bleistift im Maul, und fährt damit auf einem Blatt Papier, und man kann sie so programmieren, dass sie bestimmte geometrische (oder nicht geometrische) Figuren zeichnet. Es war im Grund ein graphisches Ausgabegerät, aber sehr intuitiv, haptisch, taktil, man konnte es angreifen, man konnte zuschauen, und das hat diese Software sehr bekannt gemacht. Jetzt gab es auf meinem Atari einen Logo-Interpreter, der war nicht gut, und kurze Zeit später haben sich zwei deutsche Mathematiker eine Logo-Implementation auf den Markt gebracht, die hieß x-Logo, "experimential Logo", und diese Sprache hat mich sehr beeindruckt, weil ich hatte plötzlich das Gefühl: ich kann mit der meine eigenen Micro-Worlds bauen, in Bezug auf musikalische Kompositionen, und habe da begonnen, mit Logo bestimmte Formalismen oder Algorithmen zu kodieren und habe damit eine ganze Zeit lang, mindestens zehn Jahre, meine Stücke komponiert. Ganz wichtig ist, dass ich in der Zeit seit 1985 Kontakte hatte mit Gottfried Michael Koenig, ein Pionier der Computer Musik, und ich habe den kennengelernt, weil mein Freund Gerhard Eckel ein Studentenaustauschsemester in Utrecht hatte. In Utrecht, in Holland, war damals das Institut "for sonology", und Koenig war dort Professor, und ich habe Gerhard besucht, und ich bin in die Bibliothek, und habe die Partituren angeschaut und fand dann dort ein Streichquartett von Gottfried Michael Koenig, und habe das kopiert, mit nach Hause genommen, und gesagt: jetzt werde ich das mal analysieren. Mich hat eben die Analyse sehr interessiert, und ich habe auch viele serielle Stücke und auch alles Mögliche, Wiener Schule analysiert, und habe versucht, das Stück zu analysieren, und bin nicht weitergekommen. Dann habe ich dem Koenig einen Brief geschrieben, und habe gesagt, ob er mir irgendwelche Hinweise geben kann. Und dann kam einige Wochen später ein ganzes dicker Brief zurück, wo er mir ganz grundlegende Dinge erklärt hat, da hat er nämlich gesagt: mich wundert es nicht, dass Sie das Stück nicht analysieren können, weil ich das mit Zufallsoperationen gemacht habe. Das war meine erste Bekanntschaft mit dem Zufall. Aber das Arge ist, dass das Stück, wenn man das hört, es klingt gar nicht zufällig, und das hat mich total interessiert, und das habe ich nicht losgelassen, und ich habe viele Konzepte, Ideen, die Koenig entwickelt hat, auch in seinen ersten Computerprogrammen, wie "Projekt 1", das ist so ein Klassiker für algorithmische Komposition, habe ich bestimmte Funktionalitäten eben in meinem Logo System implementiert, und damit so einen Werkzeugkasten angebaut, mit dem ich dann eine ganze Menge Stücke gemacht habe, natürlich nicht elektronische, sondern Instrumentalstücke. Und ich war dann zwischen 1991 und 1993 am Ircam in Paris, die haben damals diese Ircam Signal Processing Workstation entwickelt. Das war ein NeXT Computer mit einer speziellen Soundkarte, mit einem ganz tollen Prozessor, der konnte in Echtzeit Klangsynthese und Klangmanipulationen, Soundprocessing machen. Das war eine Entwicklung von einem italienischen Computerwissenschaftler namens Giuseppe Di Giugno, der hat ursprünglich die 4X Maschine entwickelt, das war im Grunde eine "PDP eleven" mit einem Signalprozessor, und wie dann die NeXT Maschine herausgekommen ist, habe ich gesagt: es ist natürlich die Zukunft, das ist portabel, es hat einen kleinen Prozessor, und man kann das auf Konzerte mitnehmen, und haben für Pierre Boulez, für sein Stück "Répons" eben die Elektronik dafür entwickelt. Und wie diese Ircam Signal Processing Workstation sozusagen in einem Beta-Stadium fertig war, haben sie verschiedene Komponisten eingeladen, junge Komponisten aus dem ganzen Welt, damit ein Stück zu machen, sie wollten es einfach testen. Und ich habe das Glück gehabt, dass ich da war. Und dann habe ich in Ircam einen Sommerkurs gemacht, und habe dort diese ganzen Dinge kennengelernt, die Softwares, die Studios, und bin auch da im Kontakt mit der Programmiersprache Max gekommen, die damals eigentlich hauptsächlich auf dieser Ircam-Workstation gelaufen ist, in einer sehr einfachen Version, das erinnert mehr an Pd als das heutige Max, und ich habe das dann für mein Stück verwendet, und ich bin so hineingekippt in dieses Max, weil ich plötzlich die Möglichkeit gesehen habe: das, was ich jahrelang am Atari gemacht habe mit Logo "out of real time", "score generation", geht plötzlich in Echtzeit, und ich könnte Resultate sofort hören, und während der Laufzeit so zu sagen eingreifen, Parameter verändern, der Klang verändert sich. Ich habe gemerkt, es wird plötzlich zu einem Instrument. Und als ich nach Hause gekommen bin, 1993, habe ich gedacht: jetzt habe ich eine tolle Möglichkeit gehabt im Ircam, aber das alles kann ich nicht zu Hause machen, ich habe nicht das Geld, mir eine Ircam Workstation zu kaufen, und Jean-Baptiste Barrière hat mir gesagt: warte fünf Jahre, in fünf Jahren hast du das zu Hause, auf deinem Laptop. Und ich sage, das kann ich mir nicht vorstellen, unmöglich. Und tatsächlich, 1998 kam der Apple mit einem G3 Prozessor, es war ein Motorola Prozessor, sehr schnell, für damalige Verhältnisse, da konnte man sozusagen ohne Signalprozessor direkt auf der CPU-Sound in Echtzeit rechnen. Und Max hat plötzlich eine Erweiterung gehabt, die ist Max MSP. Es hat das, was ich auf der Ircam Workstation gehabt habe, ich konnte dann so zu sagen ohne Hardware mein Powerbook Pro nutzen. Und ich habe das noch, das ist ein altes Teil, schwarzes Dings. Und ich habe das letztens wiedermal in die Hand genommen und eingeschaltet, weil ich suchte immer noch, und habe tatsächlich ein bestimmtes File gesucht, und es funktioniert immer noch. Es ist jetzt fast achtzehn Jahre alt, und das läuft immer noch. Das war also in kurzen Zügen der Abriss: also ich komme letztlich über die Rockmusik zur seriellen Musik, von der seriellen Musik zur elektronischen Musik, von der elektronischen Musik zur Computermusik, und von dort, aus der Partitursynthese zur Live-Elektronik. Das kann man ungefähr so als dreißigjährigen Prozess sehen.

\textbf{RV ---} Und war in diesem Prozess Echtzeit ein Traum, bevor es tatsächlich möglich gewesen ist?

\textbf{KHZ ---} Nein, überhaupt nicht, ich habe immer gedacht: warum reden die von Echtzeit? Ist mir doch egal, ob ich jetzt eine Nacht warte, bis der Rechner mir dann eine Seite, eine Partitur, Tabelle ausdruckt, die ich dann ohnehin übersetzen muss, in Notation, aber, wie ich dann gemerkt habe, ich habe damals gearbeitet mit\dots~mein erstes Programm, das ich in Max geschrieben habe, war die Lexikon-Sonate. Es war eigentlich ein Test, ich wollte Max testen. Was kann man damit komponieren? Und dann habe ich versucht, mit Max (es war damals über MIDI), mit einem angeschlossenen Piano-Sampler, wie kann ich bestimmte musikalische Strukturen erzeugen, die man am Klavier spielen kann. Und dann habe ich gemerkt plötzlich: das macht der ja plötzlich in Echtzeit, ich konnte da zuhören, wie der da spielt. Und ich kann das verändern, und plötzlich verändert sich die Harmonik oder die Geschwindigkeit, und dann habe ich gemerkt, was das bedeutet, Echtzeit\dots

\textbf{RV ---} Also: xLogo, dann Max; ich habe auch irgendwie gelesen, dass sie schon ein bisschen mit Perl und Javascript gearbeitet haben. Haben Sie auch andere Programmiersprachen probiert?

\textbf{KHZ ---} Ja. Ich habe ein bisschen SuperCollider probiert, das würde mich mehr interessieren, das heißt, das finde ich eine ganz tolle Sprache, ich habe noch zu wenig Zeit gehabt, mich damit zu beschäftigen. Und was ich jetzt sehr spannend finde ist Opusmodus. Das ist eine neue Generation von algorithmischer Kompositionssoftware, die von einem Kollektiv von französischen und polnischen Musikern entwickelt worden ist. Es ist erst seit einem Jahr auf dem Markt. Das läuft unter LISP, LISP ist die Grundlage, auf die man zugreifen kann, und es ist auf LISP aufgesetzt, und hat eine unglaublich mächtige Music XML Implementation, also man kann sozusagen musikalischen Notationen mit diesem System erzeugen, die schaut wirklich gut aus. Ein sehr sehr durchdachte Sprache mit der man eben mit Hilfe von Algorithmen (oder nicht) musikalische Notation auch direkt erzeugen kann. Das heißt, die Outputs sind unterschiedlich, es kann sein MIDI, oder Sound, oder XML, oder Notation, oder irgendwelche Grafiken, also es ist ganz offen und ganz toll konfigurierbar, hat eine riesige Bibliothek von Funktionen, die man verwenden oder erweitern kann. Und mit dem möchte ich jetzt im Sommer intensiv arbeiten. Ich habe mich in den Ferien jetzt ein paar Tage mal damit beschäftigt, hab dann mit dem Entwickler Kontakt gehabt, habe ihn nach Wien eingeladen, er hat uns dann besucht, an der Uni. Und ich möchte es gerne in der nächsten Zeit mehr benutzen, das heißt, ich komme wieder zurück quasi zur Partitursynthese, das habe ich lange Zeit nicht mehr gemacht, weil ich dann alles in Echtzeit mit Klang gemacht habe, und Live-Elektronik, aber mich interessiert wieder das andere auch.

\textbf{RV ---} Noch eine Frage über Ihr Studium: Sie haben Chemie studiert\dots

\textbf{KHZ ---} Das war in eine Schule\dots~das ist so wie Gymnasium. Oberstufe Gymnasium, mit einem Schwerpunkt Chemie. Es war ein Jahr länger, und der Abschluss war dann, sozusagen, eine Art Chemieingenieur, aber nicht universitär. Aber es war zumindest toll, weil ich habe da sehr viel naturwissenschaftliches Rüstzeug gelernt.

\textbf{RV ---} Und kurz nach dem Gymnasium haben Sie sich dann für Musikwissenschaft entschiedet?

\textbf{KHZ ---} Genau. Also ich habe dann gegen den Willem meiner Eltern, die wollten natürlich, dass ich etwas Anständiges lerne, habe ich mich dann entschieden, Musikwissenschaft zu studieren. Ich habe mich immer für Musik interessiert, ich habe auch in meiner Jugendzeit immer Musik gemacht und in Bands gespielt und Hausmusik gemacht und alles. Ich habe nie genau gewusst, was ich mache, aber Musikologie war das Naheliegendste, und ich habe dann wieder Klavierunterricht genommen bei meiner alten Lehrerin, und die hat gesagt: du musst Komposition studieren, Musikologie, das ist sehr wissenschaftlich. Also sage ich: ich weiß nicht, schaff ich das? Und die hat geantwortet: du musst es probieren, geh zu dem Professor Uhl, ruf ihn an, stell dich vor, sag ich schicke dich, und das habe ich gemacht, ich bin zu ihm Hause gefahren, er hat mich empfangen und er war schon sehr alt, und er war sehr freundlich, hat sich Sachen angeschaut, die ich komponiert habe, und gesagt: ja ja, machen Sie die Aufnahmeprüfung. Und da bin ich auch genommen worden. Also das war ganz easy eigentlich.

\textbf{RV ---} Ihre Eltern waren nicht einverstanden? Ich habe aber den Eindruck, dass sie sich für Kunst interessieren!

\textbf{KHZ ---} Ja, ja, sehr! Aber in der Zeit war das noch nicht so. Also, sie haben damals begonnen, ganz im kleinen Bereich zu sammeln, alles noch ohne Museum, sehr bescheiden.

\textbf{RV ---} Wie würden Sie Ihren musikalischen Stil beschreiben?

\textbf{KHZ ---} Es hat sich sehr stark geändert. In den 90er Jahren, also nach meinem Studium, war ich sehr beeinflusst vom Serialismus, aber eher im Sinn von Boulez, also Fortführung des Serialismus, habe sehr viel Kammermusik geschrieben, Ensemblemusik, komplex, "new complexity"-inspiriert, mich hat es fasziniert, diese Art von Ästhetik. Es war so, dass ich dann 1997 bei dem Salzburger Festspielen, wurde ich als Komponist sozusagen dort präsentiert, also "next generation", und ich hatte dort ein Portraitkonzert mit tollen Ensembles, mit tollen Dirigenten\dots~Ich war damals 37 Jahre alt und ich habe gedacht: jetzt ist es mein Höhepunkt! Und das war alles sehr gut, alles ist sehr gut gegangen, aber ich war, als das dann vorbei war, bin ich dann irgendwie in ein tiefes Loch gefallen. Ich habe mir gedacht: war es das jetzt? Ist es ein Leben? Ich sitze am Schreibtisch und schreibe Stücke, das dauert unglaublich lange, die werden dann irgendwann gespielt, dann wird es ein-, zweimal aufgeführt, und dann sitze ich hier wieder allein zu Hause und schreibe Stücke, Partituren. Früher, als ich da mit meinen Bands gespielt habe, da habe ich mindestens einmal in Monat ein Konzert gemacht. Und wir haben sehr viele Proben gehabt und voll improvisiert und interessante Sachen erlebt und jetzt sitze ich da, ganz allein in Elfenbeinturm, und schreibe meine Partituren. Und dann habe ich gesagt: ich muss da herauskommen. Ich muss wieder Performer werden auf die Bühne gehen, spielen, Live spielen. Ich habe gemerkt, ich kann kein Instrument mehr. Ich habe Klavier zwar gespielt, aber das dann aufgegeben, ich habe Kontrabass studiert, Konzertfach, auch aufgegeben, um Zeit zum Komponieren zu haben, ich habe früher E-Gitarre gespielt, das habe ich auch schon lange aufgegeben\dots~Das heißt, ich konnte zwar einige Instrumente spielen aber hatte keine Praxis. Und das war klar, dass ich als Komponist ein bestimmtes Niveau erreicht, und ich konnte dann nicht als Instrumentalist anfangen, wie ein Kind, einfachste Sachen zu spielen, das geht nicht. Das heißt, die Lösung war, ein eigenes Instrument zu finden. Und danach habe ich begonnen, wie Max MSP herausgekommen ist, ein Instrument zu bauen. Das hieß damals m@ze . Das werde ich heute am Abend spielen, das gibt es immer noch. Es ist die Erweiterung, es hat sich über viele Generationen weiterentwickelt. Und dann bin ich in dieser Zeit, nach 1998, nach Salzburg, habe ich gesagt: okay, jetzt mache ich ein großes Projekt, mit dem Titel fLOW. Das basiert auf einem Soundscape Generator, den ich in Max geschrieben habe, zu dem verschiedene Musiker improvisieren. Und ich habe das als mehrstufiges Projekt angelegt, wo ich mehrere Leute eingeladen habe, Musiker aus verschiedenen Bereichen, Jazz, experimentelle Musik, neue Musik, Klassik\dots~mit mir gemeinsam so eine fLOW-Performance zu spielen. Und dabei habe ich gelernt, wie das ist, mit Musikern aus ganz unterschiedlichen Sujets und Sprachen und Idiomatiken zu arbeiten, zu improvisieren. Und dadurch hat sich auch mein Stil als Komponist geändert. Es ist eine Musik, die heute viel mehr vom Hören ausgeht, die auch zwar konstruktive Ideen hat und Algorithmen, aber nicht mehr so hermetisch, am Schreibtisch austariert, sondern irgendwie aus einer anderen Erfahrung kommt. Das heißt, das hat sich sehr stark verändert durch die Erfahrung mit der Live-Elektronik und mit Echtzeit-Algorithmen.

\textbf{RV ---} Für wenn komponieren Sie? Welchen Hörer stellen Sie sich vor, wenn Sie komponieren oder live improvisieren?

\textbf{KHZ ---} Ich stelle mir keinen bestimmten Hörer vor, aber ich stelle mir immer Hörer vor. Also ich komponiere nicht abstrakt. Vielleicht war das früher ein bisschen anders, aber ich stelle immer vor, wie diese Musik im Raum sich entfaltet, und wie das wirkt. Das heißt, ich denke eigentlich immer beim Schreiben an den Hörer, wie sind die Zeitverläufe, kann ich das aufnehmen, kann ich das verarbeiten, kann es mich überraschen, kann ich mich langweilen. Ich denke eigentlich sehr empirisch.

\textbf{RV ---} Ich habe auch gelesen, dass sie sagten, es sei toll, zu improvisieren, aber nur wenn es ein Publikum gibt.

\textbf{KHZ ---} Genau. Es ist ein guter Punkt! Ich habe Improvisationsprojekte, auch mit dieser Agnes, die heute kommt, und wir haben nie geprobt, unser Projekt ist, wir treten vor unser Publikum und spielen "out of the blue". Es gibt immer ein Konzept, oder einen Rahmen, heute ist es Friedrich Nietzsche, ein anderer Rahmen war „Liebesgedichte“. Die Agnes, sie liest viel, sie hat eine große Literaturkenntnis, sie bringt alles Mögliche mit, Bücher, verschiedene Sachen sich angeschaut und herausgeschrieben. Sie kommt also mit ganz viel Materialien, aber sie weißt nicht, was sie verwendet, und ich weiß auch nicht, was sie verwenden wird. Und dann beginnt da so ein Spiel. Ein Spiel vor dem Publikum, wo wir uns gegenseitig so die Bälle zuschmeißen, und mit den Materialien in Echtzeit so zu sagen ein Stück komponieren. Es ist oft so, dass die Stücke, wenn man sie später anhört, und ich mache immer Aufnahmen, und schau mir das immer genau an, dass man eigentlich den Eindruck bekommt, als wären das richtige geprobte Kompositionen. Und das geht mit Ihr so gut, weil sie erstens eine unglaubliche, wahnsinnige technische Bandbreite, und sie ist sehr offen, und sie kann ganz schnell Dinge umsetzen, das heißt sie hört irgendwelche Klänge von mir, und kann darauf sofort irgendwie reagieren. Und umgekehrt kenne ich auch das, was sie macht, und kann sofort irgendwie versuchen, eine Antwort zu finden.

\textbf{RV ---} Ist Ihre Musik eine österreichische Musik?

\textbf{KHZ ---} Das ist schwer zu sagen!\dots~Also, die erste Musik, die ich gemacht habe, also nicht die Kinderwerke, das hat schon irgendwie versucht, so eine Fortsetzung zu finden von der Wiener Schule, Schönberg, Webern, Berg. Das habe ich dann aber bald abgelehnt, dann kam der Serialismus, dann waren das ganz abstrakte Konzepte, da hat es nicht mehr viel zu tun gehabt. Und jetzt kommen eigentlich Konzepte, die kommen aus anderen Regionen der Welt, da zum Beispiel (zeigt ein Instrument). Das ist eine Zither, eine chinesische Guzheng, oder im Japanischen heißt das Koto. Das hat 21 Saiten. Ich habe sie original gestimmt, das ist pentatonisch. Und es wiederholt sich in Oktaven, immer fünf Töne. Aber ich habe es so gestimmt, dass es sich nicht in Oktaven wiederholt, also das heißt Dis – Fis – Gis – H – Cis , und der nächste Ton, es beginnt nicht mit gis, sondern mit G. Das heißt, jetzt kommt C, Cis, das heißt, dadurch entsteht jetzt ein panchromatisches Total, aber man hat noch im Kleinen immer diese pentatonische Zelle, die ist immer da, aber sie ist jetzt chromatisch und harmonisch verschoben. Und ich habe ein Stück gemacht, das ist gerade veröffentlicht worden, mit Live-Elektronik, und was dabei herauskommt, klingt so, dass es mit dem Instrument wenig zu tun hat. Es ist immer so, dass der Input immer wieder an das Instrument erinnert, aber es geht sehr stark ins Orchestrale transformiert.

\textbf{RV ---} Programmieren Sie auch für Ihr Privatleben?

\textbf{KHZ ---} Ich habe früher als Webmaster gearbeitet fürs Museum. Ich habe es dann abgegeben. Erst haben es Studenten von mir gemacht, jetzt machen es meine Kinder. Aber das ist nicht wirklich programmieren in dem Sinne\dots~Und sonst nicht. Wie Sie es gesagt haben, hatte ich mit Perl ein bisschen begonnen, aber ich hatte einen Freund in Deutschland, ein Literaturwissenschaftler, der hat ein ganz interessantes Internet-Projekt mit generativer Literatur. Und er hat auch Sachen von Raymond Queneau ("Cent mille milliards de poèmes") programmiert, mit Perl, und hat eine tolle Webseite, die gibt es schon seit zwanzig Jahren, wo er diese verschiedenen Stücke, Textalgorithmen, umgesetzt hat. Und er hat mir geholfen, einige von meinen Stücken ins Web zu bekommen.

\textbf{RV ---} Haben Sie oft Literatur für Musik benutzt? Mit anderen Autoren als Borges und Joyce?

\textbf{KHZ ---} Mit der Wiener Gruppe habe ich auch gearbeitet. Und mit Andreas Okopenko natürlich. Das war für mich, der Hypertext und der Lexikon-Roman von ihm, das war ganz wichtig. Mein Klavierstück, die Lexikon-Sonate, habe ich in der Zeit gemacht, während ich in Paris war, aber nur als Etüde, um Max besser kennenzulernen. Und als ich dann zurück war, habe mich Leute angesprochen, aus Wien, Computerwissenschaftler, Künstler, die wollten dieses Buch von Okopenko als elektronisches und interaktives Buch machen. Es war vor dem World Wide Web, es gab noch keine Hyperlinks! Dann habe ich erst gemerkt, dass das, was ich in Paris zur gleichen Zeit gemacht habe, gerade in die Richtung geht, und dann hatte ich plötzlich einen Titel für das Stück gehabt: Lexikon-Roman, und dann Lexikon-Sonate. Ja, die Wiener Gruppe war wichtig. Ich hatte in dieser Zeit noch Kontakte mit zwei österreichischen Autoren meiner Generation, der eine heißt Ferdinand Schmatz, und der andere Franz Josef Czernin, und die haben auch beide mit Computerprogrammen gearbeitet, ein eigenes Computerprogramm geschrieben, POE (Poetic Oriented Evaluations). Und die haben in Grunde auch mit Strukturgeneratoren gearbeitet, oder bestimmte Algorithmen erfunden, Filter-Algorithmen, Synthese-Algorithmen, mit denen man Texte erzeugen kann. Ich bin mit denen in Kontakt gekommen, wir haben uns mehrmals getroffen, und ich bin mit einem von ihnen im ständigen Kontakt. Dann war dieser Florian Cramer, der hat diese Perl Scripts geschrieben für mich, der hat jetzt eine Professur in Rotterdam für experimentelle Literatur. Er ist auch ein Netzliteraturpionier\dots~Er ist eigentlich hauptsächlich Literaturwissenschaftler, und hat auch aber sehr viel mit so mit diesen frühen Computeralgorithmen Texte erzeugt\dots~Von dem habe ich auch sehr viel gelernt. Aber das sind so meine Bezugspunkte. Also, ich lese gern auch ganz normale Bücher!


****************************************************


LEXIKON-SONATE

\textbf{RV ---} Warum "Sonate"? "Lexikon" ist ein Verweis auf den Lexikon-Roman, und bezieht sich auch auf den modularen Inhalt\dots~aber warum "Sonate"?

\textbf{KHZ ---} EDer Titel ist in gewisser Weise ein Wortspiel, im Englischen nennt man das ein „Pun“, einen Witz. Denn das Stück bezieht sich ja auf den Lexikon-Roman von Andreas Okopenko, der wie ein Lexikon geschrieben ist. Es ist natürlich auch kein Roman, sondern es ist ein Lexikon. Und es erzeugt sozusagen im Leser erst durch das Lesen eine Restruktur des Werkes, das heißt, in dem Sinn wird die Gattung des Romans, die so ganz linear gedacht ist, und meistens in einer ganz bestimmten Entwicklung, wird darin persefliert. Und deswegen habe ich auch gesagt: okay, das Pendant zum Roman ist die Sonate. Es ist natürlich keine Sonate, aber es beinhaltet alles, was eine Sonate auch haben kann.

\textbf{RV ---} Die Sonatensatzform wäre also so wesentlich für eine Sonate, wie die Linearität für einen Roman, aber hier sind beide genauso abwesend?

\textbf{KHZ ---} In gewisser Weise, aber es ist alles drinnen. Es sind auch im Lexikon-Roman Elemente einer Reise, weil der Roman im Grunde auch oft eine Art Reise, eine Zeitreise, ist, und das ist er im Lexikonroman auch, weil es spielt auf der Donau, die Donau fließt hier vorbei (zeigt draußen), und es beschreibt eine Schifffahrt von Wien, von Nußdorf bis nach Spitz, das ist in der Wachau der letzte Ort. Und das ist eigentlich sozusagen das Backbone, also der rote Faden des Romans, diese Fahrt mit dem Schiff, mit einem Urlaubsschiff, auf der Donau, und der Protagonist dazwischen verliert sich in Tagträumen, und bekommt alle möglichen Assoziationen, es fällt ihm vieles ein aus der Vergangenheit, er sieht die Natur, berauscht sich an der Schönheit, sieht junge Mädchen, berauscht sich an der Schönheit der jungen Frauen, und fantasiert vor sich hin. Und das kann man natürlich nicht linear schreiben, sondern es sind ebenso Strukturen, die da aufploppen, und die man beliebig nachverfolgen kann.

\textbf{RV ---} Wie soll man oder muss man die Lexikon-Sonate hören? Oder wie empfehlen Sie, sie anzuhören?

\textbf{KHZ ---} Das hängt sehr vom Kontext ab, in dem sie gespielt wird. Es gibt zwei verschiedene Modi. Der eine ist der Installationsmodus, wo man das Programm einfach startet, und das beginnt für sich zu komponieren, und spielt. Das ist ein Modus, der in einer Ausstellung funktioniert, oder in einer Art Klanginstallation, also wo Leute jeder Zeit reinkommen können, und wieder herausgehen, weil es keinen Beginn und kein Ende gibt. Also, ich würde es gerne mal machen, als Installation, wenn man ein Klavier hat, einen Bösendorfer CEUS, oder ein Yamaha Disklavier, und es läuft für einige Wochen, und die Leute können in diesen Räumen hineingehen, und sich so lange aufhalten, wie sie wollen. Das ist eine Möglichkeit. Es gibt allerdings einen zweiten Modus, das ist der konzertante Modus. Den habe ich erst später entwickelt. Dass ich sozusagen die Hermetik dieses Programms aufbreche, indem ich die Automatismen zugunsten von Live-Interaktion ersetze. Und damit kann ich zum Beispiel richtige Stücke spinnen, das mache ich manchmal, dass ich mit dem Programm Lexikon-Sonate einfach eine Improvisationen mache. Und das könnte genauso ein hochvirtuoses Klavierstück sein, aus dem Bereich der New Complexity. Und da überlege ich mir oft eine Art von Ablauf, oder einen Aufbau einer formalen Entwicklung, und das kann durchaus wie ein Stück Klaviermusik gehört werden.

 \textbf{RV ---} Und was ist mit den Leuten, die das Programm herunterladen?

\textbf{KHZ ---} Die können damit machen, was sie wollen, das ist ein Geschenk. Also, man kann am Computer einfach starten und dann spielen lassen, und sich freuen, wenn im Hintergrund Klaviermusik erzeugt, oder man kann damit experimentieren. Es gibt auch bei der Shareware, also bei der Public-Domain-Version die Möglichkeit, dass man auf den Tasten bestimmte Klangstrukturen abruft, und MIDI-Controller anschließt. Also das gleiche, was ich bei meiner konzertanten Version benutze, hat der User eigentlich auch zur Verfügung, und kann sich damit sozusagen beschäftigen. Es ist wie eine Art von privaten Beschäftigen mit einer komplizierten Struktur, so wie die Betrachtung eines Bildes.

\textbf{RV ---} Was waren die wichtige Etappen in der zwanzig Jahre lang Entwicklung der Lexikon-Sonate?

\textbf{KHZ ---} Relativ zu Beginn war das Stück schon fast im gleichen Zustand, wie es heute ist, allerdings noch in diesem Installationsmodus. Der wichtigste Schritt war die Öffnung der Strukturen, der Hermetik, indem ich sozusagen direkt die Kontrolle eingebaut habe, wo ich auch ein Instrument machen kann. Das war eigentlich der wichtigste Schritt. Und dann gab es kleine Anpassungen, Optimierung des Algorithmus, aber im Grund ist das Stück in den ersten Jahren entstanden, und dann immer nur ganz leicht verändert worden.

\textbf{RV ---} Und warum ist die Möglichkeit, einen MIDI-Output zu haben, nicht mehr verfügbar?

\textbf{KHZ ---} Ich sage Ihnen genau warum. Ich bin darauf gekommen, dass Leute das benutzt haben, um damit Notationen zu generieren. Also, wie ein Notationsgenerator, und haben dann Stücke gemacht, und haben das als ihre Stücke sozusagen verkauft. Und ich fand das eine ganz blöde Idee, weil es ist absolut gegen die Idee, das Konzept, dass das eine Musik ist, die ephemer ist, die man nicht fixieren kann. Ich habe das auch selber gemacht, ich habe dasselbe Notationsprogram geladen, und habe dann eine unglaublich beeindruckend aussehende Partitur bekommen, aber das widerspricht der Idee der Musik, man soll es nicht reproduzieren, auf den Tasten, weil das kein Stück für die Pianisten ist, sondern es ist ein Stück für einen Computer. Und weil diese Leute es nicht verstanden haben, sondern das Stück benutzt haben wie ein Stück Klopapier, habe ich gesagt: okay, dann wird das abgeschaltet. Es ist ganz einfach, das zu öffnen, ja. Ich habe das ganz bewusst abgeschaltet, was den Nachteil hat, dass diese Public-Domain-Version nicht mehr mit einem MIDI-Klavier funktioniert. Und wenn jemand mich kontaktiert, der Aufführungen mit einem Klavier machen möchte, und er kann mir das glaubhaft versichern, dass er das macht, dann schicke ich ihm die offene Version. Aber mit der Netz-Version, die irgendjemand herunterladen kann, ist es nicht möglich. Es ist so, dass mittlerweile Quick-Time bessere Klaviersamples eingebaut haben, mit einer besseren Klangqualität. Aber am Anfang klang es wirklich wie eine Playstation, wie Super Mario. Ganz grässlich. Aber sie haben mittlerweile bessere Klaviersamples eingebaut. Es klingt immer noch nicht ganz überzeugend, aber es kann zumindest das Stück in irgendeiner Weise abbilden.

\textbf{RV ---} Sind solche Partituren spielbar?

\textbf{KHZ ---} Nicht genau, aber das kann man natürlich einrichten. Man kann das als Generator verwenden, um zum Beispiel Akkordstrukturen zu generieren\dots~Aber das ist nicht die Idee, außerdem gibt es immer die Frage der Autorenschaft. Ich finde, dass, wenn Leute das tun, dann sollen sie mich mindestens referenzieren.
Es müssen nicht unbedingt Tantiemen fließen, aber zumindest eine Art von Credits, und wenn die nicht da sind, dann bin ich einfach nicht bereit, solche Sachen zu teilen.

\textbf{RV ---} Ist es kein Problem, dass das Stück gleichzeitig komplex ist, aber sich nie wiederholt? Wenn man etwas Komplexes anhört, hat man oft Lust, es wieder abzuspielen, um es besser zu verstehen oder zu genießen, oder?

\textbf{KHZ ---} Das ist schon der Absicht! Also es gibt im Leben auch nicht die Möglichkeit zurückzugehen, und zu sagen "ich möchte nochmal dorthin". Also wenn Sie irgendwie einen Unfall gehabt haben, mit dem Auto, dann können Sie nicht sagen "ich gehe wieder zurück in der Stadt, und jetzt passe ich besser auf, und es passiert kein Unfall", sondern es passieren einfach Sachen, die nicht wiederholbar sind. Und das entspricht der Realität unseres Lebens, und das bildet auch die Lexikon-Sonate ab. Das heißt, es erzeugt im Hörer eine ganz andere Aufmerksamkeit, wenn er weiß, dass es sich nicht wiederholt, ich muss jeden Moment präsent sein. Und wenn etwas Tolles passiert, dann ist es ein Geschenk, so wie eine Begegnung mit einem Menschen, zufällig, die man nicht wieder hat, und an der man sich freuen muss, anstatt zu sagen: "ich kann ja alles reproduzieren".


\textbf{RV ---} Warum der Unterschied zwischen der Komplexitäten von verschiedenen Modulen? Zum Beispiel, warum ist das "Esprit"-Modul viel komplexer als das "Glissandi"-Modul?

\textbf{KHZ ---} Wie gesagt, weil diese Lexikon-Sonate versucht, bestimmte musikalische Topoi, sozusagen, zu synthetisieren. Und es gibt einfach manche, die ganz einfach sind, und andere sind einfach sehr kompliziert, aber selbst so ein einfacher „Alberti-Bass“ bei Mozart braucht natürlich etwas Kompliziertes, oder eine ausgearbeitete Melodie, und aus der Kombination von beiden entsteht dann erst das Interessante. Das ist bei der Lexikon-Sonate auch so.

\textbf{RV ---} Und warum auch der Unterschied zwischen der hohen Komplexität von der Summe von drei Modulen, und der einfachen Weise, sie zu kombinieren, das heißt, voneinander unabhängig?

\textbf{KHZ ---} Das hat auch etwas zu tun mit der Realität unseres Lebens, dass auch viele Dinge gleichzeitig passieren, die miteinander nicht verbunden sind, aber in der Wahrnehmung zu einem Gesamten werden. Das ist nicht nur ein Glaube von mir, sondern das hat auch mittlerweile die Hirnforschung bewiesen, dass der Mensch (genauer gesagt, das Gehirn) so konstruiert ist, dass es alles, was es aufnimmt, versucht, mit Bedeutung und Sinn zu füllen. Das heißt, das Gehirn versucht aus dem Chaos der Informationen, das auf ihn hereinprasselt über die Sinne, daraus viel auszufiltern, und versucht aus diesen gefilterten Informationen sinnvolle Konnexionen zu bilden. Und das ist eigentlich auch in der Lexikon-Sonate ein Thema, dass diese drei Generatoren, die gleichzeitig laufen, völlig unabhängig voneinander sind; aber wenn während des Hörens merken wir das nicht, weil wir immer damit beschäftigt sind, die Sachen miteinander zu verbinden. Und wir merken vielleicht die unterschiedliche Ebenen, wenn die Module, die man hört, sehr unterschiedlich sind, und dann kann man sehr gut folgen: hier sind die Triller, hier die Glissandi, hier die Melodie. Und dann beginnt man, wenn man die Sachen so klar unterscheiden kann, kann man sagen: jetzt möchte ich mehr die Triller hören, oder die Melodie, die Glissandi, das heißt in der Wahrnehmung kann man fokussieren und so gewisse Wege der einzelnen Strukturen, Schichten, hören und nachvollziehen.

\textbf{RV ---} Die Lexikon-Sonate wäre denn so erfolgreich, weil sie eine schöne Metapher für das Leben ist?

\textbf{KHZ ---} Ja, ich würde mich freuen wenn das auch so wahrgenommen wird. In gewisser Weise ist es natürlich ein hermetisches Stück, oder er war ursprünglich ein hermetisches Stück. Aber hinter dieser Hermetik verbirgt sich sehr viel, was mit unserem aktuellen Leben zu tun hat. Und vielleicht ist es das, wie Sie sagen, dass das Menschen anspricht. Es ist nicht eine einfache Musik, es ist komplexe Musik, aber es bildet irgendwas ab, was wir vielleicht täglich erleben, und jetzt ästhetisch transformiert, widergespiegelt bekommen.

\textbf{RV ---} Es ist also immer ein Erlebnis.

\textbf{KHZ ---} Und eine Überraschung.



GESTERN

\textbf{RV ---} Gestern trugen Sie klassische Kleider, aber im Programm des Konzerts tragen Sie ein T-Shirt (mit einer Zeichnung der Fibonacci-Spirale). Ist die Kleidung wichtig für Sie, wenn sie Konzerte machen?

\textbf{KHZ ---} Wir haben uns da schon etwas überlegt. Die Agnes hat mich gefragt, einige Tage vor dem Konzert: wie sollen wir uns anziehen? Und ich habe gesagt, ich komme ganz schwarz, weil es geht um die Nacht, und dann hat sie gesagt: wenn du in schwarz gehst, dann komme ich ganz in weiß, das wird die Polarität darstellen.

\textbf{RV ---} Das Visuelle, das Aussehen ist also wichtig in Ihrer künstlichen Praxis?

\textbf{KHZ ---} Absolut. Ich glaube, das ist ein Teil der Performanz. Wenn man an der Bühne steht, ist man nicht privat. Ich würde nicht so spielen (zeigt Alltagskleidung). Ich habe das vielleicht früher gemacht, aber ich bin darauf gekommen, dass das stimmt nicht. Wenn ich im Studio bin oder Privat, dann kann ich so gehen, aber auch wenn ich unterrichte zum Beispiel, an der Universität, habe ich immer ein Sakko an, und bin immer schwarz gekleidet, und immer elegant. Das ist das Besondere: es ist nicht der normale Alltag, sondern\dots~ – heute ist das etwas anderes. Hier bin ich ganz leger, aber, wenn ich im Unterricht oder an der Universität bin, bin ich immer korrekt angezogen. Ich habe nie Krawatten, und ich trage selten Hemden, aber ich bin immer mit Sakko und schwarzen Jeans, und schwarzem T-Shirt. Es ist die Standardkleidung, die sieht immer gleich aus.

\textbf{RV ---} Hat es Sie nicht gestört, Leute um Sie zu haben, die sich mit Fotoapparaten und Filmkameras bewegten und Lärm machten?

\textbf{KHZ ---} Nein, das waren meine Söhne, und sie sind sehr vorsichtig und sehr sensibel, und die machen das gut. Mich hat es nicht gestört. Es gibt Kameraleute, die stören mich unglaublich, weil sie einfach unsensibel sind und nicht aufpassen, aber die beiden haben das super gemacht. Ich weiß nicht, war das für das Publikum störend?

\textbf{RV ---} Nicht für das Publikum, aber ich war einfach erstaunt, dass Sie nicht aussahen, als ob es sie stören würde.

\textbf{KHZ ---} Ich habe das fast nicht wahrgenommen. Und außerdem, weil das meine Söhne sind, ist das eine Vertrautheit, fast eine Freude, wenn sie da sind. Und sie machen das oft, und sie sind selber Musiker, und sie machen elektronische Musik, das heißt, sie wissen, wie das ist, wenn man spielt und singt. Sie sind sehr sensibel und vorsichtig.

 \textbf{RV ---} Wie sind die Texte für diese Performanz ausgewählt worden?

\textbf{KHZ ---} In unserem Projekt "out of the blue" ist die Agnes immer für die Texte zuständig, und ich für die Sounds. Das heißt, dass sie sich wirklich sehr intensiv mit Nietzsche beschäftigt. Das Ganze war übrigens eine Einladung zu einem internationalen Forschungsprojekt mit verschiedenen Wissenschaftlern und Künstlern, das wir letztes Jahr gemacht hatten in Wien. Ich habe gestern am Schluss noch etwas gesagt. Zwei Menschen waren im Publikum, die haben mich eingeladen da mitzumachen, und gesagt, dass sie etwas zu Nietzsche machen, und haben mich um einen Beitrag gebeten, und ich habe gesagt: das würde ich gerne machen, aber nur mit Agnes! Wir machen eine Textperformanz mit Musik. Und so ist die Agnes zu Nietzsche gekommen, von dem sie nicht so viel kannte, aber sie hat sich sehr intensiv damit beschäftigt, hat viel gelesen, und hat aus verschiedenen Aufzeichnungen, das heißt einerseits Gedichte, philosophische Texte, Tagebuchaufzeichnungen, und Briefe, und hat daraus eine Textmontage gemacht. Und dann hatte sie solche großen Pappendeckel, und hat dann drei Stücke für drei verschiedene Teile sozusagen, und hat dort diese Texte in Kopien aufgeklebt. Das war im Grunde eine Art von "Textpartitur". Aber die waren nicht so zu lesen, dass man sie von vorne nach hinten herunterliest, sondern das waren Patches, und sie hat damit improvisiert.

\textbf{RV ---} Und ich vermute, dass es leichter ist, mit einem Text, den man kennt, zu improvisieren.

\textbf{KHZ ---} Ja, das ist toll. Die Agnes ist eigentlich eine Jazz-Sängerin, und sie macht auch viel freie Improvisationen ohne Text, nur mit der Stimme und allem möglichen, was mit der Stimme machen kann. Mit den Texten gibt es irgendwas, was einem ständig Material liefert und einen inspiriert. Und das funktioniert einfach extrem gut!

\textbf{RV ---} Genauso wie Sie mit Ihrem Instrument, oder?

\textbf{KHZ ---} Genau. Aber ich arbeite auch im Grunde mit Samples, als Basis, die werden prozessiert und miteinander gemischt, und sie macht vielleicht etwas Ähnliches mit den Texten und mit der Stimme. Es ist eigentlich sehr ähnlich.

\textbf{RV ---} Ich habe Erinnerungen an "Also sprach Zarathustra" von Richard Strauß gestern gesehen. Waren sie in Echtzeit völlig geschaffen, oder hatten Sie Strukturgeneratoren vorbereitet, um sie leichter aufrufen zu können?

\textbf{KHZ ---} Ich habe aus dem Vorspiel, aus den ersten zwei Minuten bestimmte Teile gesampelt, und damit gearbeitet. Aber ich habe auch eine Art von Struktur vorbereitet, wie eine Szene oder ein Preset, wo für eine Situation, diese bestimmten Strukturgeneratoren, die ich im Stück verwende, in dem m@ze°2 mit den bestimmten Samples gefüttert sind und mit bestimmten Parametern für die Algorithmen, zum Beispiel Transpositionen, Harmonik\dots, betrifft, kombinierbar sind, und die müssen so angepasst werden, dass sie zum Beispiel harmonisch zusammenpassen. Und da muss ich einfach die Transpositionen genau einzustellen, und in der Granular-Synthese muss ich auch sagen, in welchem Bereich die stattfindet, und wie groß die Körner (also, die Grains) sind, und in welchem Bereich die sein können, und so weiter. Und das ist aber vordefiniert, in einer Art Pre-Set, und dann weiß ich, ich brauche nicht nachdenken über abstrakte Begreife wie Grain-size, sondern ich weiß einfach, wenn ich diesen Generatoren an der Stelle aufrufe, dann macht der Generator, was ich vorher schon quasi komponiert habe, und kann damit improvisieren.

\textbf{RV ---} EMachen Sie oft ein Gespräch am Ende der Konzerte? Und bleiben Sie oft nach der Vorstellung im Konzertsaal, um mit dem Publikum zu reden?

\textbf{KHZ ---} Das hängt vom Kontext ab. Es ist das erste Mal, dass ich danach spreche. Es war einfach deswegen, weil das Stück beginnt sozusagen wirklich aus dem Nichts, und man kann nicht am Anfang herausgehen und die Rolle beenden, sagen: ich bin jetzt der Veranstalter, und erzähle etwas über das Stück, und dann verändere ich die Rolle wieder, bin jetzt der Musiker. Das ist schwierig. Deswegen habe ich es gestern nachher gemacht. Normalerweise ist es so, dass am Anfang die Agnes als Schauspielerin so zu sagen das Publikum begrüßt, und den Leuten erklärt, was wir da machen. Das Publikum weiß nicht, was wir machen, glaubt vielleicht, dass wir vorbereitete Stücke spielen und führen einfach ein Programm. Und dann erklärt sie den Leuten, dass wir mit Texten arbeiten, und dass wir frei improvisieren, und dass wir nicht wissen, was dabei herauskommt. Und dann sind erst einmal alle total irritiert, oder gespannt, und wenn es dann beginnt, merken sie: oh, schön, ja, interessant, dann ist die Verbindung mit dem Publikum geschaffen.


ECHTZEITKOMPOSITION

\textbf{RV ---} Haben Sie schon Probleme mit der Komplexität Ihrer Algorithmen gehabt? Zum Beispiel, haben Sie schon Algorithmen implementieren wollen, die eigentlich zu komplex für die Echtzeitkomposition waren?

\textbf{KHZ ---} Nie. Also wenn man sich auf diesem Echtzeitsansatz einlässt, gehen nur bestimmte Sachen. Also zum Beispiel Dinge wie Backtracking, das funktioniert in Echtzeit nicht. Man kann nicht sagen: ich generiere erstmal eine Struktur, die ich dann vergleiche und optimiere, das geht nicht. Das heißt, man muss einen ganz anderen Weg einschlagen.

\textbf{RV ---} Meiner Meinung nach ist es auch mit MAX verbunden. Ich habe den Eindruck, dass man mit MAX nicht dazu gebracht ist, sich Algorithmen mit Schleifen und so weiter zu vorstellen.

\textbf{KHZ ---} Ja, ja. Also die Struktur der Schleife, wie das in Programmiersprachen mit C oder so ist, wird anders gelöst. Das ist ein völlig anderer Ansatz. Und das ist vielleicht ganz gut, aus diesem Schleifendenken herauskommt. "for", "if", "while, oder so was\dots~Man muss das irgendwie anders lösen. Aber weil alles in Echtzeit läuft, und die Zeit vorbeigeht, ist die Zeit der drohende Faktor; das entspricht, wie man spielt oder wie man Musik macht. Beim Komponieren ist es anders. Beim Komponieren ist man im Grunde in einem anderen Modus: da kann man immer in der Zeit vor und zurück, und Beziehungen herstellen und verbessern. Aber wenn man sozusagen Live spielt oder improvisiert, dann muss man immer mit der Zeit arbeiten. Alles was passiert ist, ist nicht wiederholbar – oder man kann vielleicht versuchen, zurückzugehen, etwas Ähnliches zu machen, aber es gibt ein ständiges Weiterfließen der Zeit.

\textbf{RV ---} Wenn Sie nicht mehr in Echtzeit, sondern "out of time" komponieren, wie benutzen Sie den Computer? Was machen Sie lieber: musikalische Ideen implementieren, oder mit dem Computer spielen, um solche Ideen zu finden?

\textbf{KHZ ---} Es ist sehr unterschiedlich. Es gibt Stücke, die ich komplett ohne Computer mache. Also, die meisten meiner Instrumentalstücke mache ich nicht mit dem Computer. Ich arbeite viel mit Papier und Bleistift, auch viel mit Instrumenten, und der Computer kommt meistens in den Stücken mit Elektronik, als quasi instrumentaler Ersatz, oder als instrumentale Ebene, ins Spiel. Dann wird der Computer zum Instrument. Ich habe früher, in den 90er Jahren, viele Stücke von instrumentalen Musik mit Kompositionsalgorithmen komponiert, aber das mache ich jetzt nicht mehr. Ich werde vielleicht wieder mit solchen Dingen arbeiten, mit diesem Opus-Modus, wie ich es Ihnen erzählt habe, das würde es mich interessieren, aber in den letzten Jahren habe ich instrumentale Werke komplett ohne den Computer geschrieben. Ich bin darauf gekommen, dass ich in bestimmten Bereichen viel besser als der Computer bin, zum Beispiel, wenn es um Harmonik geht, um Tonhöhen. Dafür habe ich mehr Erfahrung, bessere Vorstellungen, mehr Fähigkeiten als der Computer. Es wäre wahrscheinlich mühsam, das zu programmieren, weil ich weder die Lust noch die Zeit habe, und ich mache es lieber selber. Mit dem Computer würde es wahrscheinlich fünfmal so lang dauern.

\textbf{RV ---} Ich habe irgendwo gelesen (und habe es komisch gefunden!), dass Sie es auch zu persönlich, fanden, von Tonhöhen und Harmonie zu sprechen.
 Was soll das bedeuten?

\textbf{KHZ ---} Ja, das ist richtig! Also, es ist wie ein geheimes Handwerk, mit dem ich einfach umgehe, und das nicht theoriefähig. Ich erinnere mich, ich hatte vor einiger Zeit ein Stück geschrieben für Toy-Piano und Ensemble, 'under wood', und da hat eine Musikwissenschaftlerin einen Aufsatz geschrieben über das Stück und hat dann eine Analyse gemacht, nur über die harmonische Struktur. Sie hat einfach unglaublich interessante Sachen herausgefunden, so wie ich denke! Sie hat ein Intervallfeld aufgezeichnet und hat mir auch gefragt: haben sie das wirklich so gemacht, und ich habe gesagt: ja ja, das stimmt, das ist richtig! (Gelächter) Aber das ist gar nicht so wichtig, das ist Handwerk, das brauche ich um die Klangräume abzustecken, und damit es auch sinnvoll zusammenklingt. Aber das ist gar nicht so wichtig, sondern das geht eigentlich mehr um die Art von Strukturen und Klänge, die entstehen, die diese Harmonik quasi eingebettet sind. Es ist nämlich interessant in der Musiktheorie – das Fach Musiktheorie- ist sehr Tonhöhen-orientiert. Die Tonhöhen werden immer analysiert. In der Musik, die ich schreibe geht es viel um Klang und um anderes, und das wird eigentlich nicht berücksichtigt. Ich habe auch gesagt, es ist etwas ganz Nebensächliches, das ist nicht im Vordergrund. Das war ihr Ansatz gewesen.

\textbf{RV ---} Und wie könnte man eine Analyse der Lexikon-Sonate, die mehr ein Prozess als ein Werk ist, machen? Wäre es zum Beispiel möglich, sie harmonisch analysieren?

\textbf{KHZ ---} Harmonisch nicht, weil die Harmonik sehr komplex ist. Die Harmonik ist in den einzelnen Generatoren unterschiedlich gestaltet. "Esprit" zum Beispiel arbeitet mit einer Art von Brown'schen Zufall, mit bestimmen Wiederholungsverboten, was Intervalle und Töne anbelangt. Aber es generiert sich sozusagen mit dem Zufallsprinzip. Und es gibt andere Generatoren, "Chords" oder "BrownChords" zum Beispiel, die mit Intervallstrukturen funktionieren, also das ist eine Harmonik auf einer höheren Ebene, hier werden die Intervallstrukturen zwar auch per Zufall bestimmt, aber es gibt ein ganz strenges Regelsystem, das bestimmte Intervallkombinationen vermeidet und ausschließt. Und dadurch entstehen noch ganz bestimmte Arten von Klängen. Sie kommen als zum Beispiel keine Dur- und Molldreiklänge vor. Es können zwar Terzenschichtungen entstehen, aber alles, was tonal klingt, wird strategisch ausgeklammert.

\textbf{RV ---} Man sollte also eine Analyse der Algorithmen machen?

\textbf{KHZ ---} Wahrscheinlich. Gar nicht jetzt des Outputs, sondern der Komposition des Algorithmus.

\textbf{RV ---} Nach Ihrer Meinung, wie wichtig ist es, zu wissen, wie ein Stück funktioniert, um es zu genießen?

\textbf{KHZ ---} Das ist eine sehr gute Frage. Also in der Postmoderne gibt es den Begriff der Doppelkodierung. Das heißt, ein Kunstwerk ist nicht eindeutig, sondern es spricht mehrere Sprachen gleichzeitig, und man kann auch als Hörer unterschiedliche Sachen hören. Es gibt den Modus des naiven Hörens, wenn man das Stück ohne Information hört, und auf sich wirken lässt, und damit etwas anfängt oder auch nicht. Und es gibt das Spezialistenhören, dass man den Leuten Informationen gibt und sie damit vielleicht schon in eine bestimmte Richtung weist, und sie mit diese Vorinformation einen anderen Fokus setzen lässt. Und dazwischen gibt es viele Möglichkeiten. Ich glaube, es ist beides möglich, und es gibt sicher mehrere Arte von Hören zwischen diesen Spezialistenhören und dem naiven, unschuldigen Hören. Aber ich sage oft, dass die Leute sollen eigentlich möglichst unvoreingenommen an das Stück herangehen. Manchmal ist es wichtig einen Kontext zuerst zu erklären. Zum Beispiel, dieses Instrument hier ist eine Pipa. Das ist ein chinesisches Instrument mit einer sehr langen Geschichte. Es ist ein Instrument, das vor allem von Frauen gespielt wird, und es ist ein sehr virtuoses Instrument. Hier ist eine arabische Oud, eine Laute. Interessant ist, dass diese Oud, die als Instrument schon tausende Jahre alt ist, sozusagen irgendwie nach China gekommen ist, und die haben das sozusagen nachgebaut, und diese Version daraus gemacht. Die haben ein anderes Tonsystem, deswegen haben sie jetzt Bünde mit fixen Tonhöhen, und die Oud hat keine Bünde, weil es diese Maqam-Struktur mit Mikrotönen gibt). Und ich habe ein Stück gemacht mit Pipa und Live-Elektronik, und das war nicht einfach ein Stück mit irgendeinem Instrument, sondern ich bin ganz bewusst auf die Geschichte dieses Instruments eingegangen, und habe einen Text gefunden, ein Gedicht von einem sehr berühmten chinesischen Dichter aus dem achten Jahrhundert, was ein Gedicht über die Pipa ist. Das ist voll mit Naturbildern und es beschreibt einen Abend im Spätsommer, wo der Mond aufgeht, und der Fluss fließt, und es gibt Freunde, die miteinander feiern, sich verabschieden, und plötzlich hören sie den Klang einer Pipa, und dann fährt er dorthin, und sieht eine Frau, die Pipa spielt, und ist ganz traurig und verzweifelt, also eine Art Liebesgeschichte. Und ich wollte eigentlich, dass dieses Instrument mit seiner Geschichte irgendwie eine Rolle spielt, und deswegen habe ich das Stück so komponiert, dass dieses Gedicht auch im Stück vorkommt. Ich habe diese Pipa-Spielerin, die chinesisch ist, gebeten, das Gedicht zu zitieren, und habe dann einige Verszeilen genommen, und habe das so gemacht, dass im Laufe des Stücks das Instrument plötzlich beginnt zu sprechen. Ich habe mit Convolution gearbeitet, an bestimmten Stellen kommt dann sozusagen aus diesem elektronischen Klang, den die Pipa auslöst, so etwas wie eine menschliche Stimme heraus. Das ist ein Stück, was eigentlich mit einer bestimmten Art von Tradition arbeitet und auch referenziert, das ist zwischen Asien und Europa, das ist ein Riesenunterschied im Denken. Und ich habe doch versucht, irgendwie eine Verbindung herzustellen. Und wir haben das Stück mehrmals in Taiwan gespielt, und das ist bei den Leuten sehr gut angekommen, weil sie das alles verstanden haben. Also wenn man es in Österreich spielt, hört man zwar, dass die Pipa plötzlich anfängt, zu reden, in einer völlig unverständlichen Sprache, aber für die Chinesen war das toll, weil sie das Gedicht auch kennen. Es gibt in jeder Kultur gewisse Gedichte, die jedes Kind kennt. Also, soviel zur Frage, wie viel Information wichtig ist: manchmal ist es wichtig, manchmal referenziere ich, manchmal möchte ich es auch vermeiden.

\textbf{RV ---} Warum zitieren Sie sehr wenig Xenakis?

\textbf{KHZ ---} Sehr gute Frage, weil es immer wieder Dinge gibt, die ich an ihm sehr interessant finde, und "Formalized Musik“ habe ich auch gelesen\dots~Ich weiß es nicht! Er ist für mich vielleicht nicht der absolute Referenzpunkt, er kommt auch von einer außermusikalischen Betrachtung. Das ist vielleicht etwas, das ist mir nicht so nah, obwohl ich sehr schätze, was er macht, aber mein Zugang ist eher ein seriell geprägter, und das hat sehr stark abgelehnt, im Grunde haben die beiden sich miteinander gewisser Weise versöhnt oder verbunden, diese Ansätze.

\textbf{RV ---} Was ist Ihre Meinung zur "Free Software"?

\textbf{KHZ ---} EPrinzipiell finde ich, dass das eine ganz großartige Idee ist. Ich meine, ich leide darunter, dass ich wenig mit graphischer Software arbeite, dass die dann unter bestimmten Umstände, wenn ich einen neuen Rechner habe, nicht mehr funktioniert, dann muss ich die neu registrieren und vielleicht auch einen neuen Code kaufen. Das ist extrem mühsam. Ich bin auch gern bereit, für Software zu zahlen. Es gibt zum Beispiel Reaper. Da kann man zahlen oder nicht, und ich habe natürlich gezahlt, weil ich finde, dass es ein gutes Programm ist, und ich weiß einfach, ich kann mich darauf verlassen, die funktioniert einfach, und ich muss mir nicht immer in das System registrieren, um es zum Laufen zu bringen. Also es hat den Vorteil, dass wenn sie gut gemacht sind, sehr verlässlich zu sein. Es gibt auch die Möglichkeit, dass man sie weiterentwickeln kann.

\textbf{RV ---} Warum benutzen Sie aber einen Mac Computer?

\textbf{KHZ ---} Weil ich damit einfach produktiver bin. Also ich bin nicht ein Apple-Befürworter, dass heißt, es musste ein Apple sein. Aber wenn ich mit Studenten, die keinen Apple, sondern einen PC haben, ist es einfach extrem mühsam, die gleichen Sachen zu machen, außer wenn die Leute extrem gut sind, und können einfach auf einer tieferen Ebene mit dem Betriebssystem gut arbeiten. Aber ein durchschnittlicher Computerbenutzer, also ein Windows-Rechner im Multimediabereich, ist auf jeden Fall einen Apple-User unterlegen. Und das hängt auch mit dem Betriebssystem zusammen, mit dem ganzen "graphical user interface", und mit der Philosophie dahinter. Es ist bei Apple einfach besser gelöst. Das Problem ist, dass Apple jetzt immer mehr zu einem Consumerprodukt wird, und vieles, was früher war, an Einstellung vorzunehmen, nicht mehr so einfach geht. Ich kann mich erinnern, dass ich früher meine alten Apples so konfiguriert habe, wie ich es brauchte, ich habe sehr viel mit dem Betriebssystem gemacht, und sie so hergerichtet, dass sie ganz auf mich zugeschnitten sind, und das ist heute sehr mühsam, und funktioniert heute auch nicht gut, und deswegen macht man das nicht, und nun muss ich wirklich mehr arrangieren, und dann, weil plötzlich Dinge eingebaut sind, wie jetzt diese Upgrades zwischen IPhone und Apple und IPad, das heißt die Cloud, und alles wird miteinander immer benutzerfreundlicher, und manchmal auch für den Poweruser ein bisschen mühsam. Das ist also der Grund, warum ich jetzt nicht mit dem neuesten Betriebssystem arbeite. Ich bin noch mit 10 und 9, weil das auch bei meinen Kollegen im Multimediabereich einfach stabiler ist. Also ich habe mittlerweile einen vier Jahren alt Computer, ich habe erst die Harddisk ersetzt durch eine SSD, und seitdem ist der Rechner um ein Vielfaches schneller, und es funktioniert alles! Also, wenn jemand mir mal sagt, einen neuen Computer für 2000 Euro zu kaufen, frage ich: wozu? Das brauche ich nicht, es läuft alles perfekt, und ich bin damit absolut zufrieden. Es geht also um die Produktivität, ich habe die Erfahrung, dass man mit dem Betriebssystem von Apple besser zurechtkommen kann als mit anderen Betriebssystemen.

\textbf{RV ---} Und gestern war Apples Apfel auf Ihren Laptop von einem "E(ART)H" Aufkleber versteckt.

\textbf{KHZ ---} Ja, ich habe es aufgeklebt. Ich denke: wenn ich Werbung mache für die Apple-Firma, dann muss sie mir etwas zahlen, zumindest einen Computer. Und wenn sie das nicht macht, okay, dann mache ich keine Werbung. Außerdem stört das auch, wenn man spielt, dass immer dieser Apfel leuchtet. Diese Werbung möchte ich nicht. Und was ich benutze, war mal so ein Aufkleber in einem Kunstprojekt, den ich einfach schön fand, und auch stimmig.

\textbf{RV ---} Wie verdienen Sie Ihren Lebensunterhalt?

\textbf{KHZ ---} Ich habe eine Professur an der Wiener Musikakademie. Das ist mein Haupteinkommen. Dann habe ich meine freie Tätigkeit als Komponist und Musiker. Und ich habe bis jetzt noch einen Tätigkeit hier im Museum für Musikveranstaltungen und Konzerte. Und früher war ich auch der Webmaster vom Museum. Dieser Job hört leider auf: ich hatte drei Jobs, und jetzt habe ich nur noch zwei.

\textbf{RV ---} Und machen Sie oft kostenlose Konzerte wie gestern?

\textbf{KHZ ---} Die Konzerte hier im Museum sind immer kostenlos. Und wenn ich woanders spiele, ist es verschieden. Also ich bin nicht der Veranstalter, es hängt von dem Veranstalter ab. Es kann sein, dass das ein ganz normales Venue ist, wo die Leute fünfzehn Euro zahlen müssen, oder es kann auch gratis sein, wenn es in einem anderen Kontext stattfindet.

\textbf{RV ---} Wie ist Ihre Meinung zum Problem der illegalen Downloads?

\textbf{KHZ ---} Meine persönliche Haltung ist, dass ich für Sachen zahle, sei es, wenn ein Musikstück mir gefällt, und ich möchte es gerne haben, oder wenn ich im Unterricht eine gewisse Aufnahme brauche, dann kaufe ich das, weil ich denke, dass das einfach wichtig für die Autoren ist, dass die das auch abgegolten bekommen. Da Sie meine Webseite kennen, wissen Sie, dass ich viele Sachen herschenke. Also wenn jemand Partituren von mir will, dann muss er sie nicht kaufen, sondern sie können frei heruntergeladen werden. Auch die Software ist bis auf wenige Ausnahmen, es gibt zwei Shareware-Softwaren, da muss man Registrierungscode zahlen, ist frei. Und das mache ich ganz bewusst, weil dadurch die Schwelle, ein Stück zu verbreiten, einfach gesenkt wird. Ich weiß als Veranstalter, wie schwierig das oft ist. Wenn man von Fausto Romitelli, einem italienischen Komponisten, eine Partitur möchte, dann muss man ihm ein Brief an Ricordi schreiben, und dann muss man zwei Monate warten bis zur Antwort, dann dauert es ein halbes Jahr, bis die das Material schicken, und dann kriegt man es vielleicht doch nicht. Ich hatte selber einen Verlag in Deutschland, der war genauso. Wenn Leute eine Ansichtspartitur haben wollten von einem Stück von mir, dann hat der Verlag die Sache am Anfang noch verschickt, und die Leute haben dann aufgrund dessen gesagt: okay, das Stück machen wir, das passt, und haben das Material, die Stimmen gekauft. Der Verlag hat es mittlerweile so gemacht, mein alter Verlag, dass jeder, der eine Partitur von mir sehen wollte, dafür zahlen musste, und meine Aufführungen von diesem Werk sind drastisch heruntergegangen. Und ich habe mich frei gekauft, dass heißt ich habe das Verlagsverhältnis beendet, habe eine bestimmte Summe zahlen müssen, und habe jetzt alles Material bekommen von denen, das waren fünfzig Kilo Papier. Und jetzt bin ich frei, ich habe meine Sachen, jetzt habe ich alles eingescannt. Und wenn Leute meine Sachen spielen, dann können sie sie wieder gratis herunterladen. Das ist eine Entscheidung von mir. Ich bin darauf gekommen, dass sich meine Musik dadurch besser verbreitet, und ich verdiene das Geld nicht durch Papier, sondern durch die Aufführungstantiemen. Also, wenn es ein richtiges offizielles Konzert ist, wird über SACEM oder GEMA oder AKM die Gebühren eingehoben, und die bekomme ich dann. Und wenn ich eine Partitur zum Beispiel fünfzehn Euro verrechne, die dann irgendwie ausgedruckt wird, dann in den Copyshop laufen muss, die dann irgendwie zu binden, und einen Umschlag zu geben, eine Rechnung zu schreiben, und dann das bei der Steuer anzumelden und fünfzig Prozent kriegt dann der österreichischen Staat. Also, das rechnet sich nicht. Der Aufwand ist in keinster Weise so, dass man davon leben kann. Deshalb sage ich: alles gratis, aber die Sachen sind registriert, sind bei der SACEM angemeldet, und ich bekomme Tantiemen dafür.

\textbf{RV ---} Was ist Ihre Meinung zum Problem des Schutzes des Privatlebens im Internet?

\textbf{KHZ ---} Ich sehe einfach, dass wenn man die Vorzüge von Google und Facebook nutzt, dass man damit auch seine Seele verkauft. Und damit muss man sagen, entweder: das akzeptiere ich, oder: ich mache es nicht. Für mich überwiegen die Vorzüge. Es ist so, dass ich sehr viel veröffentliche. Mein Facebook ist nicht ein privates Facebook, wo ich über Familiensachen oder private Dinge schreibe, sondern nur künstlerische Sachen, die mit meiner künstlerischen Arbeit zu tun haben. Und da bin ich eigentlich froh, wenn sich das verbreitet. Aber ich weiß auch natürlich, dass jede Suchanfrage, die ich mache, von Google registriert wird. Die einzige Möglichkeit ist, sich dem zu verweigern. Und ich kenne auch Leute, die sagen, sie wollen keinen Computer, kein Handy\dots~Sollen sie machen, aber die Vorzüge sind so groß, und ich brauche sie auch so, dass ich sozusagen meine Seele verkauft habe. Für mich macht das derzeit keine wirklichen Probleme. Ich bin aber schon vorsichtig, im Bezug auf Postings zum Beispiel. Ich überlege mir ganz genau, was ich schreibe, und wie ich es formuliere, und mache nicht irgendeinen Blödsinn. Mir ist schon klar, dass ich alles, das ich im Internet mache, irgendwie Teil der Internetblase wird, und irgendwo, auch wenn es jetzt nicht aktuell jemand sieht, aber das kann ganz leicht wieder herausgefunden werden. Es gibt Dinge, also Beispiele von einem deutschen Musiker, der in Amerika eingereist ist, und den sie dann festgenommen haben, und sie wussten innerhalb von fünf Minuten alles über ihn, indem sie seine ganzen sozialen Netzwerke durchforstet haben mit speziellen Algorithmen, und sofort gewusst haben, mit wem er Kontakte hat, und wie viel er mit wem telefoniert, und so weiter. Das ist eine Tatsache, die ich einfach nicht zurückverändern kann. Ich bin mit Clouddiensten sehr vorsichtig, ich verwende sie auch, aber viele Sachen auch nicht.

\textbf{RV ---} Interessieren Sie sich für die Fortschritte der künstlichen Intelligenz?

\textbf{KHZ ---} Im Künstlerischen überhaupt nicht. Ich finde es interessant, ich lese auch Fachzeitschriften, wo darüber geschrieben wird, aber im Musikalischen interessiert mich das nicht. Also "Artificial Intelligence" habe ich im künstlerischen Bereich nie interessant gefunden. Weil, dann frage ich mich, was meine Rolle als Künstler ist\dots~Zum Beispiel die Lexikon-Sonate hat nichts mit AI zu tun, sie ist absolut dumm! Aber sie macht deswegen etwas Schönes, weil ich als Erfinder des Programms Ideen von mir realisieren konnte, auch wenn der Computer sozusagen das macht, was ich ihm vorgeschlagen habe, aber auch nicht vor sich auf Dinge erfindet.

\textbf{KHZ ---} Interessieren Sie sich für Videospiele, und besonders für die Videospielmusik, die eine andere Art von algorithmischen Musik ist?

\textbf{RV ---} Es ist eigentlich interessant, aber ich habe damit noch nichts gemacht. Also, keine Ahnung. Mich haben schon Leute kontaktiert, die haben gesagt: ja, es würde unglaublich passen, also die Werkzeuge, die ich habe, ließen sich gut verwenden. Aber es hat sie noch keine konkrete Auftragssituation ergeben. Aber generell würde es mich interessieren. Ich bin zwar kein Videospieler, aber ich sehe einfach, wie toll diese künstlichen Welten jetzt geworden sind, also das ist absolut faszinierend. Und auch diese Interaktion, dass man sozusagen nicht einen Film schaut, sondern den Film selber mitgestaltet. Aber ich habe überhaupt keine Ambition für Videospiele. Mein erster Computer war dieser Atari, und es gab zwei Sachen darauf: Basic und auch ein "Textadventure". Und dieses Textadventure habe ich dann gespielt, und ich bin total süchtig geworden, und habe es dann gelöscht, und gesagt: ich werde nie mehr so was machen, weil die Gefahr sehr groß ist, dass man sich darin verliert, und stattdessen habe ich begonnen, Computeralgorithmen für Musik zu erfinden!

\textbf{RV ---} Ist die Qualität der Lautsprecher wichtig für Sie, wenn Sie Konzerte machen?

\textbf{KHZ ---} Extrem wichtig, weil ich ein großer Kritiker von normalen Lautsprechern bin. Ich finde das ein ganz scheußliches Instrument. Deswegen haben wir gestern auch diese Bose[-Lautsprecher] verwendet, diese L1. Und ich glaube, dass es genau das Richtige war, für diese Art Musik, weil sie den Klang sehr breit fächern, weil sie nicht als schwarze Würfel irgendwie den Klang wie so Klangkeil ausstrahlen, sondern sie bilden eine Fläche. Und lösen gut auf. Ich habe es eine ganz interessante Sache gefunden, wenn ich im kleinen Kontext spiele, also in kleinen Räumen, wo ich nicht dazu mit den großen Lautsprechern mitschleppen möchte, und es gibt dort ein Klavier, ein Grand Piano, dann verwende ich den Resonanzboden des Klaviers als Lautsprecher. Ich habe einen  Spezial-Lautsprecher, den kann man noch den Resonanzboden stellen, das ist ein Transducer. Und die Schwingung überträgt sich dann auf den Resonanzboden, und erzeugt damit eine Lautsprechermembran. Das kommt dann aber aus dem Klavier. Wenn man den Deckel des Klaviers aufmacht, hat man so zu sagen eine akustische Linse, und das klingt unglaublich toll.

\textbf{RV ---} Das haben Sie auch schon mit der Lexikon-Sonate gemacht!

\textbf{KHZ ---} Genau. Das ist toll, weil das wirklich wie Klavier klingt, und kommt aus dem Klavier, aber ich spiele nicht auf den Tasten, und das ist auch kein Diskklavier. Und ich habe in den letzten Jahren öfters gemacht, mit elektronischen Stücke, ohne Klavier-Kontext, und das funktioniert gut.

\textbf{RV ---} Gibt es ein Einfluss vom Rock auf Ihre heutige Musik?

\textbf{KHZ ---} Vielleicht nur, in manchen elektronischen Stücken, also diese Idee des "Sounds". Also es ist nicht der Rhythmus, oder der "Groove", sondern eher diese sehr starke Orientierung am "Sound". Das kommt vielleicht irgendwie aus der Rockmusik. Das hat sich dann aber auch erst dann wiederum in meiner Musik hineingeschlichen, als ich begonnen habe, mit Elektronik zu arbeiten, und ich habe auch viele Stücke für E-Gitarre geschrieben, auch Ensemblestücke mit E-Gitarre, und da war es sehr wichtig, diese spezielle Art von \dots~"Sound" zu verwenden allerdings jetzt ohne in irgendwelche Rockklischees zu verfallen.

\textbf{RV ---} Gibt es Erfindungen, technologische Erfindungen, die für Ihre Karriere wichtig gewesen sind?

\textbf{KHZ ---} Ich habe immer als Künstler versucht, eine Autonomie zu haben. Ich wollte nicht abhängig sein von irgendwelchen Institutionen. Und mir war es immer wichtig, dass ich alles zu Hause machen kann. Sie sehen, mein Studio besteht im Grunde aus einem Laptop. Ich brauche zum Beispiel keinen "Synthesizer". Es ist ein Zufall, dass ich da einen habe. Das ist ein uraltes Instrument, das ich vor langer Zeit einmal gekauft habe, aber ich verwende es eigentlich nicht. Also, die Technologie, die digitale Technologie hat es mir ermöglicht, ein autonomes Künstlerdasein zu machen, unabhängig von Institutionen. Diese Autonomie war auch der Grund, warum ich es immer abgelehnt habe, mit Standardsoftware zu arbeiten, also mit ProTools Logic und so weiter. Weil diese Ideen, die dahinter stehen, sind eigentlich sehr konservativ. Also, wie früher, wenn man mit Tonbandmaschinen gearbeitet hat, es ist jetzt anders organisiert, aber im Grund ist es immer die gleiche Idee: mit "Timeline" und so weiter, aber mich hat eigentlich immer ein Ansatz interessiert, der wirkliche nur mit Computer geht.

\textbf{RV ---} Gibt es auch Erfindungen, die Sie vorsehen oder erwarten?

\textbf{KHZ ---} Nein. Also, mich interessiert auch nicht diese ganze Spekulation mit "Artificial Intelligence" und, ich weiß nicht\dots~Ich sehe vieles, was passiert, und mag es jetzt nicht so, dass ich da jetzt auf jeden Zug aufspringe und alles benutzen muss. Ich habe lange viel experimentiert, mich interessiert natürlich, wie ich Algorithmen kontrollieren kann. Es gibt eine naive Vorstellung von Leuten, die meistens nicht unbedingt Musiker sind, man könnte den Klang skulptural Formen (große Bewegungen), so wie eine Skulptur aus Ton formen. Aber die Wirklichkeit ist, dass Klang ein ganz anderes Phänomen ist. Der Klang ist ein Phänomen, das nicht vergleichbar ist mit einem Stück Ton. Das ist auch nicht dreidimensional, es ist einfach viel komplexer. Und das kann man nicht einfach so, dreidimensional, in der Luft mit Händen formen und dann entsteht etwas. Ich glaube das nicht, und alles, was ich bis jetzt gesehen habe, ist einfach trivial und lächerlich. Für mich ist der Klang eine ganze komplizierte Interaktion von viele verschiedenen Parametern und Schichten, und Algorithmen, die sich gegenseitig durchdringen, und dann zuletzt den Sound als oberste Kategorie formen. Und da sind wir wieder bei der Rockmusik, weil der Sound auch ein Konzept ist, das eine Rolle bei der Rockmusik spielt. Und jetzt habe ich mich in den letzten Zeiten viel mit Kontrollen beschäftigt. Ich habe mit einem sehr ganz speziellen Zugang, weil ich mit Kontrollen arbeite, die auf der strukturellen Ebene ansetzen. MIDI-Kontrollen, die aber mit den Händen zu kontrollieren sind, und die auch zu spüren sind. Ich habe auch viel experimentiert mit Pads, mit iPads und Tablets. Es gibt auch alle möglichen Möglichkeiten, Software und Kontrollen zu erzeugen. Das Problem ist, das diese Controller auf diesen Tablets nicht taktil funktionieren, sondern nur visuell. Sie erzeugen zwar die Illusion, man hätte da irgendwelche graphischen Oberflächen, mit denen man hineingreifen kann, aber im Grunde ist es nichts anderes als dass wir hinschauen müssen, um den richtigen Punkt zu finden. Wo hingegen ich einen taktilen Controller habe, einen physikalischen Controller, mit dem ich blind spielen kann. Den kann ich in der Hand nehmen, und ich spüre einfach, es ist oben, links, rechts, und das hat etwas, was ich körperlich spüre, und was ich blind spielen kann, wo ich nicht eben hinschauen muss. Und das ist ein riesiger Unterschied, ob ich jetzt auf einem Tablet spiele, wo ich immer schauen muss, und das Schauen ist ein analytischer Sinn, das heißt, da wird immer so zu sagen die Intuition in gewisser Weise ausgehebelt. Es gibt immer eine interpretatorische Zwischenebene, wohingegen das Taktile etwas ist, was viel intuitiver und mehr körperlich ist, und direkt, also es gibt weniger über die Cortex. Und ich muss sagen, manchmal verwende ich Tablets, weil es praktisch ist, weil man sich im Raum bewegen kann, und vielleicht Dinge anstellen, und nicht immer hinlaufen muss, weil das geht über Funk. Aber fürs Spielen selber bin ich davon nicht überzeugt, und ich finde es auch ganz schrecklich, wenn dann Menschen immer auf das Tablet starren. Es ist für mich total intuitiv. Vielleicht können das andere besser verwenden, aber für mich kommt das irgendwie nicht in Frage. Was ich auch als Konzept interessant finde, sind Gesture Controllers wie "Leap Motions". Finde ich als Konzept auch interessant; das Problem ist,  dass es auch nur mit visuellem Feedback funktioniert. Das heißt, man macht zwar Bewegungen in der Luft, aber, wenn man nicht ein Bildschirm hat, und nicht sieht, wie das jetzt geändert wird, ist man auch verloren, weil man oft über die Grenzen des Videobildes hinausgeht, und dann funktioniert es gar nicht mehr. Und ich möchte nach Möglichkeit diese visuelle Komponente außer Kraft setzen. Also, die ist oft ein großes Problem, und deswegen schaue ich auch, dass sich auf meinen Interfaces meine Softwares so geschaltet sind, dass wirklich nur alles, was wirklich notwendig ist, auf dem Schirm erscheint, alles andere ist versteckt und verborgen, und das meiste funktioniert eigentlich über physikalische, taktile Kontrolle, die eine bestimmte Grenze haben. Es gibt sogenannte "Continuous-Controllers", die man in jede Richtung drehen kann, aber das Problem ist, ich weiß nie, bin ich jetzt am Maximum, bin ich jetzt am Minimum, ich muss immer wieder schauen, ich bin jetzt auf null, oder hundertsiebenundzwanzig. Und das braucht wieder die Augen, es ist schlecht. Man muss es spüren, das ist so meine Philosophie. Und ich habe gestern an zwei Stellen mit der Hand in der Luft etwas gemacht, da verwende ich die Videokamera des Laptops, und das Videobild meiner Bewegung wird analysiert und ich kann aus drei verschiedenen Dimensionen, Parameter (links/rechts, oben/unten, nah/fern) arbeiten. Ich benutze eine spezielle Form von Granular-Synthese, wo ich mich zum Beispiel durch einen Sample bewegen kann (links/rechts), durch die Höhe kann ich die Grains bestimmen, und die Entfernung, die Dichte. Und da, das habe ich einmal programmiert, und bin ich darauf gekommen, zuletzt muss ich einmal Bewegungen erfinden, die mir erlauben, damit zu musizieren. Das heißt, es war nicht so, ich mache eine Bewegung, und diese Bewegung wird in einem Klang umgesetzt, sondern im Gegenteil. Ich hatte ein System, das etwas erzeugt, und ich musste die Bewegungen erfinden, um das System damit zu spielen. Und das funktioniert. Das bedeutet für mich allerdings wieder visuelle Kontrolle, weil ich die Wellenform des Samples sehe, und ich sehe meine Bewegung, und ich sehe auch wie sich das Fenster verändert, und ich höre natürlich auch, was passiert, das heißt ich kann es auch nicht blind spielen, sondern da muss ich wieder auf dem Bildschirm schauen. Ich habe ein visuelles Feed-back, ich sehe mich selbst, dann weiß ich auch, wo meine Hand ist, was wirklich sichtbar ist, und dann ist unten die Wellenform und ich weiß, wo ich mich befinde, wie groß das Fenster ist und so weiter.

\textbf{RV ---} Was ist Ihre Beziehung zu dem Essl Museum?

\textbf{KHZ ---} Das ist ein Museum, das meine Eltern gebaut haben. Meine Eltern sammeln schon seit vielen Jahrzehnten Kunst und haben sich dann entschieden, vor zwanzig Jahren, ihre Sammlung öffentlich zu machen. Sie haben dann ein Museum gebaut, das siebzehn Jahre lang im Betrieb war, und das Problem ist, dass die Firma meines Vaters finanzielle Schwierigkeiten hatte aufgrund der Finanzkrise, sie musste verkauft werden, und die Mittel für den Betrieb des Museums waren nur private Mittel, die sind nicht mehr vorhanden, und weil wir keine Unterstützung bekommen haben von öffentlicher Hand, hat mein Vater schweren Herzens nach vielen Kämpfen und Verhandlungen entscheiden müssen, den Museumsbetrieb zu schließen, einzustellen. Das Haus wird weiter als Depot genutzt, weil es im Erdgeschoss ist, die ganze Räume im Erdgeschoss sind Depoträume, wo die Bilder professionell gelagert werden. Das war eine sehr schwere Entscheidung. Und die Konzerte, die ich hier gemacht habe, das war auch eine Schiene von experimentellen Musikkonzerten, die nicht woanders gut hineinpassen. Also, nicht in ein Konzerthaus oder eine Philharmonie, sondern zu Kleinerem, ich habe sehr viel mit Leuten gearbeitet, die also experimentell unterwegs sind, und Sachen ausprobieren, und hatte eine "Community" gebaut, die dann auch kommt und sich das anhört.

\textbf{RV ---} Und was ist die Beziehung zwischen Ihrem künstlerischen Projekt und den künstlerischen Projekten des Museums?

\textbf{KHZ ---} Als das Museum gebaut worden ist, hat der Architekt von Anfang an gesagt, dass die Musik dort eine Rolle spielen soll, und hat deswegen auch dieses Studio gebaut. Also, das ist eigentlich ein Raum, das ist ein Würfel: das ist sechs mal sechs mal sechs Meter. Und er hat gesagt: das ist die Grundstruktur des Hauses, es muss irgendwo einen Raum geben, der diese sechs mal sechs mal sechs Kantenlänge hat. Das ist ein Raum, den man nicht für ein Büro benutzen kann. Und dann hat er gesagt: da muss der Komponist hin. Und das er hat von Anfang an so gebaut, dass in den verschiedenen Räumen des Hauses Lautsprecherkabel verlegt worden sind. Ich habe am Anfang, in den ersten zehn Jahren, sehr viele Klanginstallationen hier gemacht, mit verschiedenen Künstlern. Die Idee war, Ausstellungen zu bilden, die ganz spezielle Klangenvironments schafft, und ich habe sehr viel damit experimentiert. Und ich bin darauf angekommen, dass dieser generative Ansatz sehr wichtig ist, wenn Besucher nämlich einen ständigen Loop hören, oder Leute, die im Museum arbeiten, wie Aufseher,  und sie hören über drei Monate lang alle zwei Minuten den gleichen Loop, dann werden sie am Ende ins Irrenhaus eingeliefert. Und deswegen war es ganz klar, dass die Musik, die man dort verwendet, sich ständig verändern muss und immer interessant sein muss. Und das hat mich eigentlich auch sehr stark in meiner eigenen künstlerischen Arbeit in Berührung gebracht, und ich habe auch sehr viel gelernt, aus der Erfahrung auch mit dem Publikum, wie es darauf reagiert.
